最近接触到很多关于工作流的推文，好奇使然让我进行了一番探索学习，也算是有过摸爬滚打和坎坷折腾了，在这里记录下使用情况。

## Dify工作流
> 官方网址：https://dify.ai/
> 体验地址：https://cloud.dify.ai/apps
> Github：https://github.com/langgenius/dify

先说结论：功能全，上手有难度，部署和二次开发难度大。
![image-20240621151916446](https://github.com/junglehxj/junglehxj.github.io/assets/38659409/0504aa29-98e6-47e5-86ba-8994cb6c150b)
### 在线体验
在体验地址`https://cloud.dify.ai/apps`中线上整体使用下来给我的感受是功能比较齐全，支持接入的大模型足够多，界面友好。但上手有难度，具体体现在：

1. 官方文档中有工作流节点的说明，但实际上手还是有比较大的阻力和熟悉过程，建议在官方文档的示例中直接提供示例的DSL文件，支持用户导入测试节点功能；
2. 使用下来发现工作流是偏向串联执行，如果一个节点后直接可以连多个节点，而不是串在后面但用到更前面节点的输出结果（也许有其他用户也有类似的应用场景）；
3. ==HTTP请求==的结果body看着都是字符串类型，每次使用都接了一个==代码执行==进行转换处理；
4. ==代码执行==使用单节点调试时，报错信息不够明显，错误提示的第几行等信息和编辑框里写的行数对应不起来；
5. 迭代中无法嵌套迭代。导致我目前只想到再写一个迭代的子工作流，将其嵌入到父工作流的迭代中😅;

### 开源部署
除了在线使用外，我还进行了私有化部署，其间遇到的难点和痛点也在此列举，主要用于提醒自己：
1. 后端`Python/Flask`，配置环境和执行均正常；
2. 前端`Next.js/React`，艰难配置、未正常执行（本人后端出身，学过Vue，对这块不熟😵）；
3. 在有网络环境且有代理的情况下使用docker部署，真心很丝滑。（可恶的docker源竟然都用不了了，然而我在Ubuntu系统装docker也是遇到了一些麻烦，在公司内网的CentOS装docker就很畅通）；
4. 由于公司内网的限制，配置nginx转发时最好有一个统一前缀，加这个前缀也让我学习到`next.js`中的文件系统路径，以及配置文件`next.config.js`中`basePath`的用法；
5. 由于前端的本地环境缺失，进行上述改动后，均使用开源文件中的DockerFile重新制作了镜像，再迁移到公司内网中使用，路径曲折；
6. `dify`项目中内嵌的大模型使用方法均是联网的，如何使用本地模型目前我能想到的是用==HTTP请求==的方式，但流式述出又要如何处理呢？

整体来讲，有这样一个开源框架还是非常不错的，使用这些前沿的平台和框架时，除了需要有编程底子让自己能够上手且正常使用外，还需要有一些发掘需求、奇思妙想的能力。

### 自己搭建
![image-20240621161022940](https://github.com/junglehxj/junglehxj.github.io/assets/38659409/eaefaf64-a35f-40fa-8f03-9c2df9937b82)
这是我自己尝试搭建的工作流，提取HackerNews的Stories。大模型接入的部分没有放在这里，这个工作流看着是很简单的，但自己却花了蛮多时间😑，下次好好努力。
[HackeNews提取ask.zip](https://github.com/user-attachments/files/15924800/HackeNews.ask.zip)





